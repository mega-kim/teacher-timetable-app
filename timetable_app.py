import pandas as pd
import streamlit as st
import re
import io
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
import json 

# --- 0. Streamlit ì•± ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(layout="wide")

# --- CSS ìŠ¤íƒ€ì¼ ì£¼ì… (í°íŠ¸, ê·¸ë¦¬ë“œ ê³ ì •) ---
CUSTOM_CSS = """
<style>
    /* ì „ì²´ ê¸°ë³¸ í°íŠ¸ í¬ê¸° ì¤„ì´ê¸° (ê¸°ë³¸ 16px -> 14px) */
    body, .stApp, .stWidget {
        font-size: 14px;
    }
    /* ìœ„ì ¯ ë¼ë²¨(stRadio, stSelectbox) í°íŠ¸ í¬ê¸° */
    .st-bu, .st-ag, .st-at, .st-bq, .st-ar, .st-as, label, .st-emotion-cache-1y4p8pa {
        font-size: 14px !important;
    }
    /* í—¤ë” í¬ê¸° ì•½ê°„ ì¡°ì ˆ */
    h1 { font-size: 2.0rem; }
    h2 { font-size: 1.75rem; }
    h3 { font-size: 1.25rem; }
    
    /* ì‹œê°„í‘œ ê·¸ë¦¬ë“œ ê³ ì • (ê°€ì¥ ì¤‘ìš”) */
    table.timetable-grid { /* CSS í´ë˜ìŠ¤ ì§€ì • */
        table-layout: fixed; /* í…Œì´ë¸” ë ˆì´ì•„ì›ƒ ê³ ì • */
        width: 80%; /* (ìˆ˜ì •ë¨) 100% -> 80%ë¡œ ê°€ë¡œ í­ ì¶•ì†Œ */
        border-collapse: collapse;
        /* (ì¶”ê°€) í…Œì´ë¸”ì„ ìš°ì¸¡ íŒ¨ë„ì˜ ì¤‘ì•™ì— ë°°ì¹˜ (ì„ íƒ ì‚¬í•­) */
        /* margin-left: auto; */
        /* margin-right: auto; */
    }
    table.timetable-grid th { /* ìš”ì¼ í—¤ë” (ì›”~ì¼) */
        /* (ìˆ˜ì •ë¨) ë„ˆë¹„ ê³„ì‚° ë³€ê²½ (80% ê¸°ì¤€) */
        width: 12.8%; 
        text-align: center; /* í—¤ë” ì¤‘ì•™ ì •ë ¬ */
        vertical-align: middle; /* í—¤ë” ì¤‘ì•™ ì •ë ¬ */
        font-size: 1.0rem; 
        background-color: #f0f2f6;
        padding: 8px;
        border: 1px solid #ddd;
    }
    table.timetable-grid td { /* ì‹œê°„í‘œ ì¹¸ (ì˜¤ì „/ì˜¤í›„/ì €ë…) */
        height: 90px; /* ê³ ì • ë†’ì´ 90px */
        vertical-align: middle; /* ì„¸ë¡œ ì¤‘ì•™ ì •ë ¬ */
        text-align: center; /* ê°€ë¡œ ì¤‘ì•™ ì •ë ¬ */
        padding: 8px;
        border: 1px solid #ddd;
        width: 12.8%;
        word-wrap: break-word; 
    }
    /* ì‹œê°„ëŒ€ í—¤ë” (ì˜¤ì „/ì˜¤í›„/ì €ë…) - êµµê²Œ */
    table.timetable-grid tr th:first-child, table.timetable-grid tr td:first-child {
        font-weight: bold;
        text-align: center;
        vertical-align: middle; /* ì„¸ë¡œ ì¤‘ì•™ ì •ë ¬ */
        background-color: #f0f2f6;
        width: 10%; /* ì‹œê°„ëŒ€ ì»¬ëŸ¼ ë„ˆë¹„ */
    }
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
# --- CSS ë ---

st.title("ê°•ì‚¬ë³„ ì¶œê°• í˜„í™© í†µí•© ì‹œê°„í‘œ ğŸ“Š")

# --- 1. Google Sheets ì¸ì¦ ë° ì—°ê²° ---
try:
    creds_dict = {
        "type": st.secrets["gcp_type"],
        "project_id": st.secrets["gcp_project_id"],
        "private_key_id": st.secrets["gcp_private_key_id"],
        "private_key": st.secrets["gcp_private_key"].replace('\\n', '\n'), 
        "client_email": st.secrets["gcp_client_email"],
        "client_id": st.secrets["gcp_client_id"],
        "auth_uri": st.secrets["gcp_auth_uri"],
        "token_uri": st.secrets["gcp_token_uri"],
        "auth_provider_x509_cert_url": st.secrets["gcp_auth_provider_x509_cert_url"],
        "client_x509_cert_url": st.secrets["gcp_client_x509_cert_url"],
        "universe_domain": st.secrets["gcp_universe_domain"]
    }
    
    sheet_url = st.secrets["google_sheet_url"]
    admin_password = st.secrets["admin_password"]
    
    scopes = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    credentials = Credentials.from_service_account_info(creds_dict, scopes=scopes)
    gc = gspread.authorize(credentials)
    
    sh = gc.open_by_url(sheet_url)
    ws_master = sh.worksheet('master_data')
    ws_address = sh.worksheet('address_book')
    
    try:
        ws_mapping = sh.worksheet('subject_mapping')
    except gspread.exceptions.WorksheetNotFound:
        st.error("ì˜¤ë¥˜: Google Sheetì— 'subject_mapping' íƒ­ì´ ì—†ìŠµë‹ˆë‹¤! ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        st.stop()

except Exception as e:
    st.error("Google Sheets ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Streamlit Cloudì˜ 'Secrets' ì„¤ì •ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.error(f"ì˜¤ë¥˜: {e}")
    st.stop()

# --- 2. ì—‘ì…€ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data
def convert_df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    processed_data = output.getvalue()
    return processed_data

# --- 3. Google Sheet ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ( 'ì¤‘ë³µ ì œê±°' ë¡œì§ ) ---
@st.cache_data(ttl=60) # 60ì´ˆë§ˆë‹¤ ìºì‹œ ê°±ì‹ 
def load_data_from_gs():
    """Google Sheetì—ì„œ 3ê°œì˜ íƒ­ì„ ëª¨ë‘ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜"""
    master_df = pd.DataFrame(ws_master.get_all_records())
    address_df = pd.DataFrame(ws_address.get_all_records())
    mapping_df = pd.DataFrame(ws_mapping.get_all_records())
    
    # ë¡œë“œ ì‹œì ì— ì¦‰ì‹œ ì¤‘ë³µ ì œê±°
    if not master_df.empty:
        key_columns = ['ì—°ë„', 'ì›”', 'ê°•ì‚¬', 'ê³¼ëª©', 'ìš”ì¼', 'ì‹œê°„ëŒ€', 'í•™ì›', 'ê°•ì¢Œêµ¬ë¶„']
        existing_key_columns = [col for col in key_columns if col in master_df.columns]
        master_df = master_df.drop_duplicates(subset=existing_key_columns, keep='first')
    
    # 'ìíƒ ì£¼ì†Œ' ë³‘í•© ë¡œì§
    if not master_df.empty:
        if not address_df.empty and 'ê°•ì‚¬ëª…' in address_df.columns:
            if 'ìíƒ ì£¼ì†Œ' not in address_df.columns:
                st.warning("ê²½ê³ : ì£¼ì†Œë¡(address_book) ì‹œíŠ¸ì— 'ìíƒ ì£¼ì†Œ' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ê°’ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                address_df['ìíƒ ì£¼ì†Œ'] = 'ì •ë³´ ì—†ìŒ'
                
            if 'ê°•ì‚¬ëª…' not in master_df.columns:
                master_df['ê°•ì‚¬ëª…'] = master_df['ê°•ì‚¬']
            
            master_df = pd.merge(master_df, address_df[['ê°•ì‚¬ëª…', 'ìíƒ ì£¼ì†Œ']], on='ê°•ì‚¬ëª…', how='left')
            master_df['ìíƒ ì£¼ì†Œ'] = master_df['ìíƒ ì£¼ì†Œ'].fillna('ì •ë³´ ì—†ìŒ')
        else:
            if not address_df.empty:
                 st.warning("ê²½ê³ : ì£¼ì†Œë¡(address_book) ì‹œíŠ¸ì— 'ê°•ì‚¬ëª…' ì»¬ëŸ¼ì´ ì—†ì–´ ì£¼ì†Œë¡ì„ ë³‘í•©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            master_df['ìíƒ ì£¼ì†Œ'] = 'ì •ë³´ ì—†ìŒ'
            
    # 'ì˜ì—­' ë° 'ì„ íƒê³¼ëª©' ë³‘í•© ë¡œì§
    if not master_df.empty and not mapping_df.empty:
        if 'ì„ íƒê³¼ëª©' not in mapping_df.columns or 'ì˜ì—­' not in mapping_df.columns:
            st.warning("ê²½ê³ : 'subject_mapping' íƒ­ì— 'ì„ íƒê³¼ëª©' ë˜ëŠ” 'ì˜ì—­' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            master_df['ì˜ì—­'] = 'ê¸°íƒ€'
            master_df['ì„ íƒê³¼ëª©'] = master_df['ê³¼ëª©'] 
        else:
            master_df = pd.merge(master_df, mapping_df[['ì„ íƒê³¼ëª©', 'ì˜ì—­']], left_on='ê³¼ëª©', right_on='ì„ íƒê³¼ëª©', how='left')
            master_df['ì˜ì—­'] = master_df['ì˜ì—­'].fillna('í•œêµ­ì‚¬') # 'ê¸°íƒ€' -> 'í•œêµ­ì‚¬'ë¡œ
    else:
        master_df['ì˜ì—­'] = 'ê¸°íƒ€'
        master_df['ì„ íƒê³¼ëª©'] = master_df['ê³¼ëª©']
    
    # 'ìµœì´ˆ ê°œê°•ì¼' ê³„ì‚°
    if 'ê°œê°•ì¼' in master_df.columns:
        master_df['ê°œê°•ì¼_dt'] = pd.to_datetime(master_df['ê°œê°•ì¼'], errors='coerce')
        df_first_appearance = master_df.groupby('ê°•ì‚¬')['ê°œê°•ì¼_dt'].min().reset_index()
        df_first_appearance = df_first_appearance.rename(columns={'ê°œê°•ì¼_dt': 'ìµœì´ˆ ê°œê°•ì¼'})
        master_df = pd.merge(master_df, df_first_appearance, on='ê°•ì‚¬', how='left')
    else:
        master_df['ìµœì´ˆ ê°œê°•ì¼'] = pd.NaT

    return master_df, mapping_df 

# --- 4. ì‹ ê·œ ê°•ì¢Œ íŒŒì¼ ê°€ê³µ í•¨ìˆ˜ (ê¸°ì¡´ ë¡œì§) ---
def process_new_lecture_file(file):
    df_list = []
    try:
        file_bytes = file.getvalue()
        file_extension = file.name.split('.')[-1].lower()
        engine = 'openpyxl'
        if file_extension == 'xls':
            engine = 'xlrd'
        df = pd.read_excel(io.BytesIO(file_bytes), header=1, engine=engine)
    except Exception as e:
        if "Expected BOF record" in str(e) or "Unsupported format" in str(e) or "corrupt file" in str(e):
            st.warning(f"'{file.name}'ì€(ëŠ”) Excel í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. HTMLë¡œ ì½ê¸°ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
            try:
                try: df_list_html = pd.read_html(io.BytesIO(file_bytes), header=1, encoding='utf-8')
                except UnicodeDecodeError: df_list_html = pd.read_html(io.BytesIO(file_bytes), header=1, encoding='cp949')
                if not df_list_html: raise ValueError("HTMLì—ì„œ í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                df = df_list_html[0]
                df = df[pd.to_numeric(df['No'], errors='coerce').notna()]
            except Exception as html_e:
                st.error(f"'{file.name}' íŒŒì¼ ë¡œë“œ ìµœì¢… ì‹¤íŒ¨. HTML ì˜¤ë¥˜: {html_e}")
                return pd.DataFrame()
        else:
            st.error(f"'{file.name}' íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}.")
            return pd.DataFrame()
    df = df[df['íŒë§¤'] != 'íê°•']
    df = df[~df['ê°•ì¢Œêµ¬ë¶„'].astype(str).str.contains('ì½”ì–´')]
    df['ê°œê°•ì¼'] = pd.to_datetime(df['ê°œê°•ì¼'], errors='coerce')
    df['ì—°ë„'] = df['ê°œê°•ì¼'].dt.year.fillna(0).astype(int).astype(str)
    df['ì›”'] = df['ê³¼ì •'].astype(str).str.extract(r'(\d+ì›”)')
    missing_month = df['ì›”'].isnull()
    df.loc[missing_month, 'ì›”'] = df[missing_month]['ê°œê°•ì¼'].dt.month.fillna(0).astype(int).astype(str) + 'ì›”'
    df['ì›”'] = df['ì›”'].replace('0ì›”', pd.NA)
    df['í•™ì›'] = df['í•™ì›'].astype(str).str.replace('ëŸ¬ì…€', '').str.replace('CORE', '').str.strip()
    df_exploded = df.assign(ìˆ˜ì—…ì‹œê°„_ë¶„ë¦¬=df['ìˆ˜ì—…ì‹œê°„'].astype(str).str.split('\n')).explode('ìˆ˜ì—…ì‹œê°„_ë¶„ë¦¬')
    df_exploded['ìš”ì¼'] = df_exploded['ìˆ˜ì—…ì‹œê°„_ë¶„ë¦¬'].str.extract(r'([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼])')
    df_exploded['ì‹œì‘ì‹œê°„'] = df_exploded['ìˆ˜ì—…ì‹œê°„_ë¶„ë¦¬'].str.extract(r'(\d{2}:\d{2})')
    def map_time_slot(start_time):
        if pd.isna(start_time): return pd.NA
        try: hour = int(start_time.split(':')[0])
        except: return pd.NA
        if hour < 12: return 'ì˜¤ì „'
        elif 12 <= hour < 18: return 'ì˜¤í›„'
        else: return 'ì €ë…'
    df_exploded['ì‹œê°„ëŒ€'] = df_exploded['ì‹œì‘ì‹œê°„'].apply(map_time_slot)
    final_columns = ['ì—°ë„', 'ì›”', 'ê°•ì‚¬', 'ê³¼ëª©', 'ìš”ì¼', 'ì‹œê°„ëŒ€', 'í•™ì›', 'ê°•ì¢Œêµ¬ë¶„', 'ê°œê°•ì¼']
    df_processed = df_exploded[final_columns].copy()
    df_processed = df_processed.dropna(subset=['ì—°ë„', 'ì›”', 'ê°•ì‚¬', 'ìš”ì¼', 'ì‹œê°„ëŒ€'])
    df_processed = df_processed.drop_duplicates()
    df_processed['ê°œê°•ì¼'] = df_processed['ê°œê°•ì¼'].astype(str)
    return df_processed

# --- 5. ê´€ë¦¬ì ëª¨ë“œ ('DB ê°±ì‹ ' ë¡œì§) ---
st.sidebar.header("ğŸ‘¨â€ğŸ’¼ ê´€ë¦¬ì ëª¨ë“œ")
password_attempt = st.sidebar.text_input("ë¹„ë°€ë²ˆí˜¸ ì…ë ¥", type="password")

if password_attempt == admin_password:
    st.sidebar.success("ê´€ë¦¬ì ì¸ì¦ ì„±ê³µ!")
    
    st.sidebar.subheader("ì‹ ê·œ ë°ì´í„° ê°±ì‹ ")
    new_lecture_files = st.sidebar.file_uploader(
        "ì‹ ê·œ ê°•ì¢Œ ë‚´ì—­ íŒŒì¼ (XLS/XLSX/HTML)",
        type=["xls", "xlsx"],
        accept_multiple_files=True,
        help="ê°±ì‹ í•  ì›”ì˜ ê°•ì¢Œ ë‚´ì—­ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
    )
    new_address_file = st.sidebar.file_uploader(
        "ì‹ ê·œ ê°•ì‚¬ ì£¼ì†Œë¡ íŒŒì¼ (XLS/XLSX)",
        type=["xls", "xlsx"],
        help="ê°±ì‹ í•  ê°•ì‚¬ ì£¼ì†Œë¡ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. 'ê°•ì‚¬ëª…', 'ìíƒ ì£¼ì†Œ' ì»¬ëŸ¼ í•„ìˆ˜."
    )
    
    if st.sidebar.button("[DB ê°±ì‹ í•˜ê¸°]"):
        with st.spinner("ë°ì´í„°ë² ì´ìŠ¤ ê°±ì‹  ì¤‘... (ê¸°ì¡´ ë°ì´í„° + ì‹ ê·œ ë°ì´í„°)"):
            try:
                st.write("1/4: ê¸°ì¡´ ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì¤‘...")
                existing_master_df = pd.DataFrame(ws_master.get_all_records())
                
                st.write("2/4: ì‹ ê·œ ê°•ì¢Œ íŒŒì¼ ê°€ê³µ ì¤‘...")
                new_dataframes = []
                for file in new_lecture_files:
                    processed_df = process_new_lecture_file(file)
                    new_dataframes.append(processed_df)
                
                if not new_dataframes:
                    st.error("ê°±ì‹ í•  ì‹ ê·œ ê°•ì¢Œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()
                    
                new_master_df = pd.concat(new_dataframes, ignore_index=True)
                
                st.write("3.1/4: ë°ì´í„° ë³‘í•© ì¤‘...")
                combined_master_df = pd.concat([existing_master_df, new_master_df], ignore_index=True)
                combined_master_df['ê°œê°•ì¼'] = combined_master_df['ê°œê°•ì¼'].astype(str)
                
                key_columns = ['ì—°ë„', 'ì›”', 'ê°•ì‚¬', 'ê³¼ëª©', 'ìš”ì¼', 'ì‹œê°„ëŒ€', 'í•™ì›', 'ê°•ì¢Œêµ¬ë¶„']
                existing_key_columns = [col for col in key_columns if col in combined_master_df.columns]
                combined_master_df = combined_master_df.drop_duplicates(subset=existing_key_columns, keep='first')
                st.write(f"3.2/4: ì¤‘ë³µ ì œê±° ì™„ë£Œ (ê¸°ì¤€: {len(existing_key_columns)}ê°œ í‚¤)")
                
                st.write("3.3/4: 'master_data' ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì¤‘...")
                ws_master.clear()
                ws_master.update([combined_master_df.columns.values.tolist()] + combined_master_df.astype(str).values.tolist())
                
                if new_address_file:
                    st.write("4/4: 'address_book' ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì¤‘...")
                    address_df = pd.read_excel(new_address_file, engine='openpyxl' if new_address_file.name.endswith('xlsx') else 'xlrd')
                    if 'ê°•ì‚¬ëª…' not in address_df.columns or 'ìíƒ ì£¼ì†Œ' not in address_df.columns:
                        st.error("ì—…ë¡œë“œí•œ ì£¼ì†Œë¡ íŒŒì¼ì— 'ê°•ì‚¬ëª…' ë˜ëŠ” 'ìíƒ ì£¼ì†Œ' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤! ì£¼ì†Œë¡ì´ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        ws_address.clear()
                        ws_address.update([address_df.columns.values.tolist()] + address_df.astype(str).values.tolist())
                else:
                    st.warning("ì£¼ì†Œë¡ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'address_book' ì‹œíŠ¸ëŠ” ê°±ì‹ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                st.success("ë°ì´í„°ë² ì´ìŠ¤ ê°±ì‹  ì™„ë£Œ!")
                st.info("ë°ì´í„° ìºì‹œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤. 1ë¶„ í›„ ì•±ì´ ìë™ ê°±ì‹ ë©ë‹ˆë‹¤.")
                st.cache_data.clear()
                st.rerun()

            except Exception as e:
                st.error(f"DB ê°±ì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

elif password_attempt:
    st.sidebar.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")

# --- 6. ë©”ì¸ í™”ë©´ (ë°ì´í„° ë¡œë“œ ë° í•„í„°) ---
try:
    master_data, mapping_data = load_data_from_gs() 
except Exception as e:
    st.error("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ì ëª¨ë“œì—ì„œ DB ê°±ì‹ ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.error(f"ì˜¤ë¥˜: {e}")
    st.stop()

if master_data.empty:
    st.warning("ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê´€ë¦¬ì ëª¨ë“œì—ì„œ ë°ì´í„°ë¥¼ ê°±ì‹ í•´ì£¼ì„¸ìš”.")
    st.stop()
if mapping_data.empty:
    st.warning("ê²½ê³ : 'subject_mapping' ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. í•„í„°ê°€ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# --- 7. ìƒë‹¨ í•„í„° ( 'ê°•ì‚¬ ì„ íƒ ìœ ì§€' ë¡œì§ ì¶”ê°€ ) ---
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì„ íƒëœ ê°•ì‚¬)
if 'selected_instructor' not in st.session_state:
    st.session_state.selected_instructor = None

all_years = sorted(master_data['ì—°ë„'].astype(str).unique(), reverse=True)
selected_year = st.selectbox("ì—°ë„ ì„ íƒ", all_years)

all_months = sorted(master_data[master_data['ì—°ë„'].astype(str) == selected_year]['ì›”'].astype(str).unique())
selected_month = st.selectbox("ì›” ì„ íƒ", all_months)

filtered_data = master_data[
    (master_data['ì—°ë„'].astype(str) == selected_year) & 
    (master_data['ì›”'].astype(str) == selected_month)
]

# --- 8. ì¢Œì¸¡ íƒìƒ‰ íŒ¨ë„ ( 'í•„í„° ë¡œì§' ì „ì²´ ìˆ˜ì •ë¨ ) ---
# (ìˆ˜ì •ë¨) col1, col2 ë¹„ìœ¨ [1, 1.5]ë¡œ ë³€ê²½
col1, col2 = st.columns([1, 1.5]) 

with col1:
    st.header("Step 2: ê°•ì‚¬ íƒìƒ‰")

    # --- [í•„í„° 1] ì˜ì—­ ì„ íƒ ---
    hardcoded_area_order = ['[ì˜ì—­ ì „ì²´]', 'êµ­ì–´', 'ìˆ˜í•™', 'ì˜ì–´', 'ì‚¬íšŒíƒêµ¬', 'ê³¼í•™íƒêµ¬', 'ë…¼ìˆ &ì œ2ì™¸êµ­ì–´', 'í•œêµ­ì‚¬']
    
    available_areas_in_mapping = list(mapping_data['ì˜ì—­'].unique())
    available_areas_in_data = list(master_data['ì˜ì—­'].unique())
    all_available_areas = sorted(list(set(available_areas_in_mapping + available_areas_in_data)))

    area_list = [area for area in hardcoded_area_order if area in all_available_areas]
    other_areas = [area for area in all_available_areas if area not in hardcoded_area_order and area != '[ì˜ì—­ ì „ì²´]']
    area_list.extend(other_areas)
    
    selected_area = st.selectbox("1. ì˜ì—­ ì„ íƒ", area_list)

    if selected_area == '[ì˜ì—­ ì „ì²´]':
        data_after_area_filter = filtered_data
    else:
        data_after_area_filter = filtered_data[filtered_data['ì˜ì—­'] == selected_area]

    # --- [í•„í„° 2] ì„ íƒê³¼ëª© ì„ íƒ ---
    subject_list = []
    disable_subject_filter = False
    
    if selected_area == '[ì˜ì—­ ì „ì²´]':
        subject_list = ['[ê³¼ëª© ì „ì²´]']
        disable_subject_filter = True
    elif selected_area in ['êµ­ì–´', 'ìˆ˜í•™', 'ì˜ì–´', 'í•œêµ­ì‚¬']:
        subject_list = [selected_area] # *** (ìˆ˜ì •ë¨) '[...ë§Œ ë³´ê¸°]' -> 'êµ­ì–´' ë“±ìœ¼ë¡œ ë³€ê²½
        disable_subject_filter = True
    else:
        # ì‚¬íƒ, ê³¼íƒ, ë…¼ìˆ 
        subjects_in_mapping = list(mapping_data[mapping_data['ì˜ì—­'] == selected_area]['ì„ íƒê³¼ëª©'].unique())
        subjects_in_data = list(data_after_area_filter[data_after_area_filter['ì˜ì—­'] == selected_area]['ê³¼ëª©'].unique())
        ordered_subject_list = [subject for subject in subjects_in_mapping if subject in subjects_in_data]
        other_subjects = sorted([subject for subject in subjects_in_data if subject not in ordered_subject_list])
        
        if selected_area == 'ë…¼ìˆ &ì œ2ì™¸êµ­ì–´':
             subject_list = ordered_subject_list + other_subjects
        else: # ì‚¬íƒ, ê³¼íƒ
             subject_list = ['ì „ì²´'] + ordered_subject_list + other_subjects
    
    selected_subject = st.selectbox("2. ì„ íƒê³¼ëª© ì„ íƒ", subject_list, disabled=disable_subject_filter)

    # 2ì°¨: 'ì„ íƒê³¼ëª©'ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§
    if selected_area == '[ì˜ì—­ ì „ì²´]' or disable_subject_filter:
        data_after_subject_filter = data_after_area_filter
    elif selected_subject == 'ì „ì²´': 
        data_after_subject_filter = data_after_area_filter
    else:
        data_after_subject_filter = data_after_area_filter[data_after_area_filter['ê³¼ëª©'] == selected_subject]

    # --- [í•„í„° 3] ê°•ì‚¬ëª… ê²€ìƒ‰ ---
    search_query = st.text_input("3. ê°•ì‚¬ëª… ê²€ìƒ‰ ğŸ”")

    if search_query:
        searched_data = data_after_subject_filter[
            data_after_subject_filter['ê°•ì‚¬'].astype(str).str.contains(search_query, case=False)
        ]
    else:
        searched_data = data_after_subject_filter
    
    # --- [ê²°ê³¼] ê°•ì‚¬ ëª©ë¡ ( 'ì„ íƒ ìœ ì§€' ë¡œì§ ì¶”ê°€ ) ---
    instructors_list = sorted(searched_data['ê°•ì‚¬'].unique())

    if not instructors_list:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        selected_instructor = None
        st.session_state.selected_instructor = None # ì„ íƒ ì´ˆê¸°í™”
    else:
        default_index = 0
        if st.session_state.selected_instructor in instructors_list:
            default_index = instructors_list.index(st.session_state.selected_instructor)
        
        month_start_date = pd.to_datetime(f'{selected_year}-{selected_month.replace("ì›”","")}-01', format='%Y-%m-%d', errors='coerce')
        def format_instructor_name(instructor_name):
            first_lecture_date = master_data.loc[master_data['ê°•ì‚¬'] == instructor_name, 'ìµœì´ˆ ê°œê°•ì¼'].min()
            if pd.notna(first_lecture_date) and pd.notna(month_start_date):
                if first_lecture_date >= month_start_date:
                    return f"{instructor_name} (ì‹ ê·œ)"
            return f"{instructor_name} (ê¸°ì¡´)"

        selected_instructor = st.radio(
            f"ê°•ì‚¬ ì„ íƒ (ê²°ê³¼: {len(instructors_list)}ëª…)", 
            instructors_list,
            format_func=format_instructor_name,
            index=default_index, 
            key='instructor_radio'
        )
        st.session_state.selected_instructor = selected_instructor # ì„¸ì…˜ì— í˜„ì¬ ì„ íƒ ì €ì¥

# --- 9. ìš°ì¸¡ ì‹œê°„í‘œ íŒ¨ë„ ( 'ìš”ì¼ í—¤ë” ì‚­ì œ' ë° 'ê³¼ëª©ëª… ìˆ¨ê¸°ê¸°' ìˆ˜ì •ë¨ ) ---
with col2:
    if selected_instructor:
        st.header(f"ğŸ—“ï¸ {selected_instructor} ê°•ì‚¬ ì‹œê°„í‘œ ({selected_year} / {selected_month})")

        instructor_data = filtered_data[filtered_data['ê°•ì‚¬'] == selected_instructor]

        days = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        time_slots = ['ì˜¤ì „', 'ì˜¤í›„', 'ì €ë…']
        
        try:
            # (ìˆ˜ì •ë¨) 'format_cell' í•¨ìˆ˜ë¡œ ê³¼ëª©ëª… ìˆ¨ê¸°ê¸° ë¡œì§ êµ¬í˜„
            def format_cell(x):
                entries = []
                for _, row in x.iterrows():
                    subject_display = "" # Default: empty
                    # (ìˆ˜ì •) 'ì˜ì—­'ì´ êµ­/ìˆ˜/ì˜ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ê³¼ëª©ëª… í‘œì‹œ
                    if row['ì˜ì—­'] not in ['êµ­ì–´', 'ìˆ˜í•™', 'ì˜ì–´']:
                        subject_display = f"{row['ê³¼ëª©']}<br>"
                    
                    entries.append(
                        f"<b>{row['í•™ì›']}</b><br>{subject_display}({row['ê°•ì¢Œêµ¬ë¶„']})"
                    )
                return "<br><br>".join(entries)

            timetable_agg = instructor_data.groupby(['ì‹œê°„ëŒ€', 'ìš”ì¼']).apply(format_cell).reset_index(name='ìˆ˜ì—…ì •ë³´')
            
            timetable_pivot = timetable_agg.pivot(index='ì‹œê°„ëŒ€', columns='ìš”ì¼', values='ìˆ˜ì—…ì •ë³´')
            
            # (ìˆ˜ì •ë¨) 'ìš”ì¼' ìƒìœ„ í—¤ë” ì‚­ì œ
            timetable_pivot.columns.name = None
            
            display_df = timetable_pivot.reindex(index=time_slots, columns=days, fill_value="")
            
            display_df = display_df.reset_index().rename(columns={'index': 'ì‹œê°„ëŒ€'})
            
            st.markdown(display_df.to_html(escape=False, na_rep="", classes="timetable-grid", index=False, header=True), unsafe_allow_html=True)
        
        except Exception as e:
            st.error(f"ì‹œê°„í‘œë¥¼ ê·¸ë¦¬ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.dataframe(instructor_data)

        st.subheader("ê°•ì‚¬ ì •ë³´")
        if not instructor_data.empty:
            instructor_info_full = master_data[master_data['ê°•ì‚¬'] == selected_instructor]
            if not instructor_info_full.empty:
                instructor_info = instructor_info_full.iloc[0]
                
                first_lecture_date = instructor_info['ìµœì´ˆ ê°œê°•ì¼']
                is_new = False
                if pd.notna(first_lecture_date) and pd.notna(month_start_date):
                    if first_lecture_date >= month_start_date:
                        is_new = True
                
                st.markdown(f"""
                - **ìíƒ ì£¼ì†Œ**: {instructor_info['ìíƒ ì£¼ì†Œ']}
                - **ê°•ì‚¬ ìƒíƒœ**: {"ì‹ ê·œ ê°•ì‚¬" if is_new else "ê¸°ì¡´ ê°•ì‚¬"} (ìµœì´ˆ ê°œê°•ì¼: {first_lecture_date.strftime('%Y-%m-%d') if pd.notna(first_lecture_date) else '-'} )
                """)
            
            st.subheader("ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
            excel_data = convert_df_to_excel(instructor_data)
            st.download_button(
                label="[ì„ íƒí•œ ê°•ì‚¬ì˜ í˜„ì¬ ë°ì´í„°] ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œ",
                data=excel_data,
                file_name=f"{selected_year}_{selected_month}_{selected_instructor}_ì‹œê°„í‘œ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.info("ì„ íƒëœ ê°•ì‚¬ì— ëŒ€í•œ í‘œì‹œí•  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
